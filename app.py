import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration
from streamlit.components.v1 import html
import av

# Ø¥Ø¹Ø¯Ø§Ø¯ WebRTC
RTC_CONFIGURATION = RTCConfiguration({
    "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
})

# ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ YOLO (ØªØ£ÙƒØ¯ Ø¥Ù† paste.pt Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹)
model = YOLO("best.pt")
model.fuse()

# Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª ÙˆØ£Ù„ÙˆØ§Ù†Ù‡Ø§
CLASS_NAMES = ["microsleep", "neutral", "yawning"]
COLOR_MAP = {
    "microsleep": (0, 0, 255),
    "neutral": (0, 255, 0),
    "yawning": (0, 0, 255)
}

# Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØª Ù…Ù† GitHub (Ø¨Ø¯Ù‘Ù„Ù‡ Ø¨Ø±Ø§Ø¨Ø·Ùƒ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±)
BUZZER_URL = "https://raw.githubusercontent.com/mostafa7hmmad/yolov8-drowsiness-detection-system/main/1.mp3"

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø§Ø²Ø± (ÙÙŠ Ø§Ù„Ù…ØªØµÙØ­)
def play_buzzer():
    html(f"""
        <audio id="buzzer" autoplay loop>
            <source src="{BUZZER_URL}" type="audio/mpeg">
        </audio>
        <script>
            var buzzer = document.getElementById("buzzer");
            if (buzzer) buzzer.play();
        </script>
    """, height=0)

# Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø§Ø²Ø±
def stop_buzzer():
    html("""
        <script>
            var buzzer = document.getElementById("buzzer");
            if (buzzer) buzzer.pause();
        </script>
    """, height=0)

# Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
class FastVideoProcessor(VideoTransformerBase):
    def __init__(self):
        self.frame_skip = 2
        self.counter = 0
        self.prev_result = None

    def transform(self, frame):
        img = frame.to_ndarray(format="bgr24")
        small_frame = cv2.resize(img, (320, 240))

        self.counter += 1
        if self.counter % self.frame_skip == 0:
            results = model(small_frame, verbose=False)[0]
            self.prev_result = results
        else:
            results = self.prev_result

        detected_non_neutral = False

        if results:
            for box, cls in zip(results.boxes.xyxy, results.boxes.cls):
                x1, y1, x2, y2 = map(int, box)
                label_index = int(cls)
                if label_index >= len(CLASS_NAMES): continue
                label = CLASS_NAMES[label_index]
                color = COLOR_MAP[label]
                x1, y1, x2, y2 = [int(x * 2) for x in (x1, y1, x2, y2)]

                cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
                cv2.putText(img, label, (x1, y1 - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

                if label != "neutral":
                    detected_non_neutral = True

        # Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ø§Ø²Ø±
        st.session_state['play_buzzer'] = detected_non_neutral
        return img

# Streamlit ÙˆØ§Ø¬Ù‡Ø©
st.set_page_config(page_title="YOLOv8 Drowsiness Detection", layout="wide")
st.title("ğŸ§  Real-time Drowsiness Detection with Sound Alert")

# Ø²Ø± Ù…Ù„Ø¡ Ø§Ù„Ø´Ø§Ø´Ø©
st.markdown("""
<button onclick="document.querySelector('video').requestFullscreen()" style="
    display:block;
    margin:auto;
    background-color:#0a84ff;
    color:white;
    padding:10px 30px;
    border-radius:12px;
    font-size:16px;
    border:none;
    cursor:pointer;">ğŸ“º Fullscreen Camera</button>
""", unsafe_allow_html=True)

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø­Ø§Ù„Ø©
if "play_buzzer" not in st.session_state:
    st.session_state["play_buzzer"] = False

# Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
webrtc_streamer(
    key="fast-stream",
    video_processor_factory=FastVideoProcessor,
    rtc_configuration=RTC_CONFIGURATION,
    media_stream_constraints={"video": {"width": 640, "height": 480}, "audio": False},
    async_processing=True
)

# ØªØ´ØºÙŠÙ„ Ø£Ùˆ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø§Ø²Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ù„Ø©
if st.session_state["play_buzzer"]:
    play_buzzer()
else:
    stop_buzzer()
